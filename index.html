<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>ICCV CVAMD 2023</title>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.2.0/css/bootstrap.min.css">
  <link href='http://fonts.googleapis.com/css?family=Roboto:400,700' rel='stylesheet' type='text/css'>
  <link href="css/style.css" rel="stylesheet" type="text/css">
</head>

<body>


<div class="navbar navbar-default navbar-fixed-top">
  <div class="nav-container">
    <div class="navbar-header">
      <a class="navbar-brand" href="#" style="font-size:30px">ICCV CVAMD 2023</a>
      <button class="navbar-toggle" type="button" data-toggle="collapse" data-target="#navbar-main">
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
          <span class="icon-bar"></span>
      </button>
    </div>

    <a href="#overview" class="btn" style="font-size:16px">Overview</a>
    <a href="#program" class="btn" style="font-size:16px">Program</a>
    <a href="#invited_speakers" class="btn" style="font-size:16px">Invited Speakers</a>
    <a href="#call_for_paper" class="btn" style="font-size:16px">Submissions</a>
    <a href="#important_dates" class="btn" style="font-size:16px">Important Dates</a>
    <a href="#organizers" class="btn" style="font-size:16px">Organizers</a>
    <a target="_blank" rel="noopener noreferrer" href="https://bionlplab.github.io/2023_ICCV_CVAMD/" class="btn" style="font-size:16px">CXR-LT Competition</a>
  </div>
</div>

<div class="container">
  <p><br/></p>
  <div class="row">
      <div class="col-xs-12">
          <img class="img2" src="images/teaser.png">
          <div class="centered">
            <br><br><br><br>
            <span style="font-size: 36px"><b>Computer Vision for Automated Medical Diagnosis</b></span><br><br>
            <span style="font-size: 24px"><i><b>ICCV 2023 Workshop</b></i></span>
            <table border="0" align="center">
              <tr>
              <h2><td colspan="3" align="center">
                Location: <b>Room S01, Paris Convention Center</b><br>
                Time: <b>October 2, 2023</b><br>
                Zoom link: <b><a href="https://weillcornell.zoom.us/s/98111410365" target="_blank">https://weillcornell.zoom.us/s/98111410365</a></b>
              </td>
              </h2>
              </tr>
            </table>
          </div>
          </div>
      </div>
  </div>
  <!-- <p><br/></p> -->
<br>


<div class="container", id="overview">
  <h2>Overview</h2>
  <div class="overview">
    <p>Over the past few decades, medical imaging techniques, such as chest X-rays, computed tomography (CT), magnetic resonance imaging (MRI), positron emission tomography (PET), mammography, and ultrasound, and have been used for the early detection, diagnosis, prognosis, and treatment of diseases. Various medical imaging analysis problems, such as medical image registration, detection of anatomical and cellular structures, tissue segmentation, have achieved state-of-the-art performances by applying computer vision techniques. However, how to securely and reliably deploy these technologies for facilitating further disease diagnosis and treatment planning remains an open question.</p>

    <p>In this workshop, we aim to bring together researchers in computer vision, machine learning, healthcare, medicine, and clinical fields to facilitate discussions including related challenges, possible solutions and future directions. We hope that the proposed workshop is fruitful in offering a step toward building autonomous clinical decision systems with a higher-level understanding of medical computer vision.</p>
  </div>
</div>


<br>

<div class="container", id="program">
  <h2>Program</h2>
  Zoom link for remote attendees: <b><a href="https://weillcornell.zoom.us/s/98111410365" target="_blank">https://weillcornell.zoom.us/s/98111410365</a></b>
  <div class="program">
    <h3 style="color: #084DF6">Morning Session #1 [09:00 – 10:40]</h3>
    
  
    <b>09:00 – 09:10</b> | Welcome and introduction 
    <br>
    <b>09:10 – 09:40</b> | Invited Talk #1: <b>Sumit Chopra</b>  (in person)

    <details>
      <summary>
        <b>09:40 – 10:10</b> | Invited Talk #2: <b>Holger Roth</b>  (in person):
        <b><i>Federated Medical Image Analysis</i></b>
      </summary>
      <p>
        <b>Abstract:</b> The COVID-19 pandemic has emphasized the need for large-scale collaborations between the clinical and scientific communities to tackle global healthcare challenges. However, regulatory constraints around data sharing and patient privacy might hinder access to data representing diverse and clinically relevant patient populations. Federated learning (FL) technology allows us to work around such restrictions while respecting patient privacy. This talk will show how FL was used to predict clinical outcomes in patients with COVID-19 while allowing collaborators to retain governance over their data. Furthermore, I will introduce several recent advances in FL, including quantifying potential data leakage, automated machine learning (AutoML), federated neural architecture search (NAS), and personalization that can allow us to build more accurate and robust AI models for medical imaging, large-language-modeling, and beyond.
        </p>
      </p>
    </details>

    <details>
      <summary>
        <b>10:10 – 10:40</b> | Invited Talk #3: <b>Marinka Zitnik</b> (remote):
        <b><i>Knowledge Graph AI for Diagnosing Patients with Rare Genetic Diseases</i></b>
      </summary>
      <p>
        <b>Abstract:</b> There are more than 7,000 rare diseases, collectively affecting 300-400 million people worldwide, yet each disease has a very low prevalence, involving no more than 50 per 100,000 individuals. Due to their low prevalence, most front-line clinicians lack disease experience, resulting in numerous specialty referrals and expensive clinical workups for patients across multiple years and institutions. Such challenges make rare disease diagnosis extremely difficult; approximately 70% of individuals seeking a diagnosis and up to 50% of the suspected Mendelian conditions remain undiagnosed. These diagnostic odysseys can lead to redundant testing or unnecessary medical procedures, inappropriate or delayed disease management, and irreversible disease progression if the time window for intervention is missed. We introduce SHEPHERD, a deep learning approach for multi-faceted rare disease diagnosis. SHEPHERD is guided by existing knowledge of diseases, phenotypes, and genes to learn novel connections between a patient’s clinico-genetic information and phenotype and gene relationships. We train SHEPHERD exclusively on simulated patients and independently evaluate on an external patient cohort representing 299 diseases in the Undiagnosed Diseases Network. SHEPHERD excels at several diagnostic facets: performing causal gene discovery, retrieving “patients-like-me” with the same gene or disease, and providing interpretable characterizations of novel disease presentations. SHEPHERD demonstrates the potential of artificial intelligence to accelerate the diagnosis of rare disease patients and has implications for using deep learning on medical datasets with very few labels. This is joint work with Emily Alsentzer, Michelle M. Li, Shilpa N. Kobren, Zak Kohane, and the Undiagnosed Diseases Network.
        </p>
      </p>
    </details>
    <br>

    <!-- <br> -->
    <h3 style="color: #084DF6">Oral Session #1 [10:40 – 11:00]</h3>
    <b>10:40 – 10:45</b> | Oral Presentation #1: <b>Zdravko Marinov</b> (in person): <i><b> Mirror U-Net: Marrying Multimodal Fission with Multi-task Learning for Semantic Segmentation in Medical Imaging</b></i> <br>
    <b>10:45 – 10:50</b> | Oral Presentation #2: <b>Gabriel Mejia</b> (in person): <i><b>SEPAL: Spatial Gene Expression Prediction from Local Graphs</b></i> <br>
    <b>10:50 – 10:55</b> | Oral Presentation #3: <b>Xinrong Hu</b> (remote): <i><b>Contrastive Image Synthesis and Self-supervised Feature Adaptation for Cross-Modality Biomedical Image Segmentation</b></i> <br>
    <b>10:55 – 11:00</b> | Oral Presentation #4: <b>Ziqi Yu</b> (remote): <i><b>Cross-grained Contrastive Representation for Unsupervised Lesion Segmentation in Medical Images</b></i> <br>

    <!-- <br> -->
    <!-- <h3 style="color: #084DF6">Poster Session #1 & Coffee Break [11:00 – 12:00]</h3> -->

    <details>
      <summary>
        <h3 style="color: #084DF6">Poster Session #1 & Coffee Break [11:00 – 12:00]</h3>
      </summary>
      <p>
        <a href="posters/ICCV_MirrorUNet_pdf24 - Zdravko Marinov.pdf"><u>1. Mirror U-Net: Marrying Multimodal Fission with Multi-task Learning for Semantic Segmentation in Medical Imaging</u></a>  <br>
        <a href="posters/Poster_upload - Gabriel Mateo Mejia.pdf"><u>2. SEPAL: Spatial Gene Expression Prediction from Local Graphs</u></a>  <br>
        3. Do CNNs need some Attention? Boosted Organ Segmentation with Attention Maps from Self-Supervised ViTs <br>
        <a href="posters/poster_CVAMD_paper06_12092023 - Linh Le.pdf"><u>4. RRc-UNet 3D for lung tumor segmentation from CT scans of Non-Small Cell Lung Cancer patients</u></a>  <br>
        <a href="posters/Chest_Xray_Poster - Faisal Ahmed.pdf"><u>5. Topo-CXR: Chest X-ray TB and Pneumonia Screening with Topological Machine Learning</u></a> <br>
        <a href="posters/cvamd_poster - Xinrong Hu.pdf"><u>6. Contrastive Image Synthesis and Self-supervised Feature Adaptation for Cross-Modality Biomedical Image segmentation</u></a>  <br>
        <a href="posters/poster-CVAMD-12 - z yu.pdf"><u>7. Cross-grained Contrastive Representation for Unsupervised Lesion Segmentation in Medical Image</u></a>  <br>
        8. Semi-supervised Quality Evaluation of Colonoscopy Procedures <br>
        9. Ensuring a connected structure for Retinal Vessels Deep-Learning Segmentation <br>
        <a href="posters/CLIPath - Jeff Lai.pdf"><u>10. CLIPath: Fine-tune CLIP with Visual Feature Fusion for Pathology Image Analysis Towards Minimizing Data Collection Efforts</u></a>  <br>
        <a href="posters/CVAMD-16-poster - reza azad.pdf"><u>11. Implicit Neural Representation in Medical Imaging: A Comparative Survey</u></a>  <br>
        <a href="posters/CVAMD2023_poster_paperID18 - Sriprabha Ramanarayanan.pdf"><u>12. HyperCoil-Recon: A Hypernetwork-based Adaptive Coil Configuration Task Switching Network for MRI Reconstruction</u></a>  <br>
        <a href="posters/CVAMD_Poster_19 - Ashay Patel.pdf"><u>13. Self-Supervised Anomaly Detection from Anomalous Training Data via Iterative Latent Token Masking</u></a>  <br>
        <a href="posters/iccv23w_poster_22 - Haochen Zhang.pdf"><u>14. Robust AMD Stage Grading with Exclusively OCTA Modality Leveraging 3D Volume</u></a>  <br>
        <a href="posters/Segmentation-based Assessment of Tumor-Vessel Involvement for Surgical Resectability Prediction of Pancreatic Ductal Adenocarcinoma - Christiaan Viviers.pdf"><u>15. Segmentation-based Assessment of Tumor-Vessel Involvement for Surgical Resectability Prediction of Pancreatic Ductal Adenocarcinoma</u></a>  <br>
        <a href="posters/CVAMD-27, Sharing is Caring Concurrent Interactive Segmentation and Model Training using a Joint Model - Ivan Mikhailov.pdf"><u>16. Sharing is Caring: Concurrent Interactive Segmentation and Model Training using a Joint Model</u></a>  <br>
        <a href="posters/CVAMD-29 - Sudipta Roy(1).pdf"><u>17. Robust MSFM Learning Network for Classification and Weakly Supervised Localization</u></a>  <br>
        <a href="posters/cvamd2023_poster_v2.3 - 정재민.pdf"><u>18. Standardized Image-Based Polysomnography Database and Deep Learning Algorithm for Sleep Stage Classification</u></a>  <br>
        <a href="posters/CVAMD2023_HwihunJeong_BlindHarmony - ­정휘훈 _ 학생 _ 전기·정보공학부.pdf"><u>19. BlindHarmony: “Blind” Harmonization for multi-site MR Image processing via Flow model</u></a>  <br>
        <a href="posters/Template_poster_CREATIS_ICCV_2023 (1) - nicolas “Emoptisie”.pdf"><u>20. SP3D: Learning Keypoint Detection and Description in 3D Medical Images</u></a>  <br>
        <a href="posters/poster_38 - qi wang.pdf"><u>21. DISGAN: Wavelet-informed discriminator guides GAN to MRI image Super-resolution with noise cleaning</u></a>  <br>
        <a href="posters/ICCV_CVAMD_Poster_40 - Adrit Rao.pdf"><u>22. Studying the Impact of Augmentations on Medical Confidence Calibration</u></a>  <br>
        <a href="posters/ICCV_CVAMD_Poster_2023_final - Weichen Huang.pdf"><u>23. Multimodal Contrastive Learning and Tabular Attention for Automated Alzheimer's Disease Prediction </u></a>  <br>
        <a href="posters/ePoster_CVAMD23_v4 - Ye Li.pdf"><u>24. Weakly Semi-supervised Detector-based Video Classification with Temporal Constraints for Lung Ultrasound</u></a>  <br>
        <a href="posters/Order Learning Vision Transformer for Cancer Classification in Pathology Images - ‍이주천[ 대학원석사과정재학 _ 전기전자공학과 ].pdf"><u>25. Order-ViT: Order Learning Vision Transformer for Cancer Classification in Pathology Images</u></a>  <br>
        <a href="posters/paper_id_46_iccv_cvamd - SHUBHAM KUMAR(1).pdf"><u>26. MIND THE CLOT: AUTOMATED LVO DETECTION ON CTA USING DEEP LEARNING</u></a>  <br>
        <a href="posters/CVAMD2023-poster - Anh Tu Nguyen.pdf"><u>27. A Comparative Study of Vision Transformer Encoders and Few-shot Learning for Medical Image Classification</u></a>  <br>
        28. RheumaVIT: transformer-based model for Automated Scoring of Hand Joints in Rheumatoid Arthritis <br>
        <a href="posters/CVAMD-49 - Sudipta Roy.pdf"><u>29. AW-Net: A Novel Fully Connected Attention-based Medical Image Segmentation Model</u></a>  <br>
        30. Geodesic Regression Characterizes 3D Shape Changes in the Female Brain During Menstruation <br>
        <a href="posters/Poster_ICCVworkshop_2023 - Laura Galvez Jimenez.pdf"><u>31. Computational Evaluation of the Combination of Semi-Supervised and Active Learning for Histopathology Image Segmentation with Missing Annotations </u></a>  <br>
        <a href="posters/ICCV2023-2 - Quang-Hien Kha.pdf"><u>32. Towards Robust Natural-looking Mammography Lesion Synthesis On Ipsilateral Dual-views Breast Cancer Analysis</u></a>  <br>
        <a href="posters/ICCV-poster - SIQI WANG.pdf"><u>33. End-to-End Deep Learning for Reconstructing Segmented 3D CT Image from Multi-Energy X-ray Projections</u></a>  <br>
        <a href="posters/Yourim Choi_ICCV CVAMD - ­최유림 _ 학생 _ 데이터사이언스학과.pdf"><u>34. SlAction: Non-intrusive, Lightweight Obstructive Sleep Apnea Detection using Infrared Video</u></a>  <br>
        <a href="posters/ICCV_CVAMD_Poster - JJ L.pdf"><u>35. Combating Coronary Calcium Scoring Bias for Non-gated CT by Semantic Learning on Gated CT</u></a>  <br>
        36. Comprehensive Multimodal Segmentation in Medical Imaging: Combining YOLOv8 with SAM and HQ-SAM Models <br>
        37. Semantic Parsing of Colonoscopy Videos with Multi-Label Temporal Networks <br>
        <a href="posters/iccv_poster_final - Sidney Bender.pdf"><u>38. Towards Fixing Clever-Hans Predictors with Counterfactual Knowledge Distillation</u></a>  <br>
        <a href="posters/poster-CVAMD-62 - Eva Pachetti.pdf"><u>39. Causality-Driven One-Shot Learning for Prostate Cancer Grading from MRI</u></a>  <br>
        <a href="posters/sharpy_poster_ver3 - Vanessa Wirth.pdf"><u>40. ShaRPy:Shape Reconstruction and Hand Pose Estimation From RGB-D with Uncertainty</u></a> <br>
        41. An Empirical Analysis for Zero-Shot Multi-Label Classification on COVID-19 CT Scans and Uncurated Reports <br>
        42. Fusion Approaches to Predict Post-stroke Aphasia Recovery from Multimodal Neuroimaging Data <br>
        43. Automated Biomarker Detection in Diagnostics of Colorectal Cancer <br>
        <a href="posters/CVAMD-72-poster - reza azad.pdf"><u>44. Self-supervised Semantic Segmentation: Consistency over Transformation</u></a>  <br>
        <a href="posters/ICCV_poster_final - Milad Sikaroudi.pdf"><u>45. ALFA: Leveraging All Levels of Feature Abstraction for Enhancing the Generalization of Histopathology Image Classification Across Unseen Hospitals</u></a>  <br>
        46. Pathology-Based Ischemic Stroke Etiology Classification via Clot Composition Guided Multiple Instance Learning <br>
        47. Enhancing Medical Image Segmentation: Optimizing Cross-Entropy Weights and Post-Processing with Autoencoders <br>
        <a href="posters/LookingBeyondWhatYouSee_Poster_CVMAD_2023 - Dana Moukheiber.pdf"><u>48. Looking Beyond What You See: An empirical analysis on subgroup intersectional fairness for multi-label chest x-rays classification using social determinants of racial health inequities</u></a>  <br>
        <a href="posters/Poster_ICCV_Ivan-2 - Billy Peralta.pdf"><u>49. Double pre-training for detecting fetal heart diseases with Deep Learning: A Chilean case</u></a>  <br>
        <a href="posters/CVAMD83 - Sajith R.pdf"><u>50. Using Large Text To Image Models with Structured Prompts for Skin Disease Identification: A Case Study</u></a>  <br>
        <a href="posters/chexfusion poster - Dongkyun Kim.pdf"><u>51. CheXFusion: Effective Fusion of Multi-View Features using Transformers for Long-Tailed Chest X-Ray Classification</u></a>  <br>
        <a href="posters/poster_CVAMD - 박원기(1).pdf"><u>52. Robust Asymmetric Loss for Multi-Label Long-Tailed Learning</u></a>  <br>
        53. How Can We Tame the Long-Tail of Chest X-ray Datasets? <br>
        54. Effect of Stage Training for Long-Tailed Multi-Label Image Classification <br>
        <a href="posters/Poster - feng hong.pdf"><u>55. Bag of Tricks for Long-Tailed Multi-Label Classification on Chest X-Rays </u></a>  <br>
        56. Advanced Augmentation and Ensemble Approaches for Classifying Long-Tailed Multi-Label Chest X-Rays <br>
        57. An Optimized Ensemble-based Framework for Multi-Label Long-Tailed Classification on Chest X-rays <br>
        58. Multi-Label Long-Tailed Classification on Chest X-Rays by upgrading ML-GCN <br>
        <a href="posters/ICCV_poster_cvamd-96-new-A0 - Changhyun Kim.pdf"><u>59. Chest X-Ray Feature Pyramid Sum Model with Diseased Area Data Augmentation Method</u></a>  <br>
      </p>  
    </details>
    
    <!-- <br> -->
    <h3 style="color: #084DF6">Lunch Break [12:00 – 13:00]</h3>

    <!-- <br> -->
    <h3 style="color: #084DF6">CXR-LT Competition Session [13:00 – 13:20]</h3>
    <b>13:00 – 13:10</b> | CXR-LT Competition Summary <br>
    <b>13:10 – 13:15</b> | CXR-LT Oral Presentation #1: <b>Dongkyun Kim: CheXFusion</b> (in person): <i><b>Effective Fusion of Multi-View Features using Transformers for Long-Tailed Chest X-Ray Classification</i></b><br>
    <b>13:15 – 13:20</b> | CXR-LT Oral Presentation #2: <b>Nguyen Mau Trong Hieu</b> (in person): <i><b>Advanced Augmentation and Ensemble Approaches for Classifying Long-Tailed Multi-Label Chest X-Rays</i></b><br>
    <!-- <br> -->
    <h3 style="color: #084DF6">Afternoon Session #1 [13:20 – 14:50]</h3>
    
    <b>13:20 – 13:50</b> | Invited Talk #4: <b>Liyue Shen</b>  (remote)<br>

    <details>
      <summary>
        <b>13:50 – 14:20</b> | Invited Talk #5: <b>Shandong Wu</b> (remote):
        <b><i>Advance Medical Imaging AI for Clinical and Translational Applications</i></b>
      </summary>
        <p>
          <b>Abstract:</b> There are numerous efforts on technical development and translation of AI/ML in the medical imaging domain. In addition to some of the classic challenges such as small datasets, limited annotations, imbalanced classes, how to gain and enhance trust from the users and practitioners of medical AI/ML is an emerging topic, and key for successful applications of AI to patient care. In this talk, the speaker will elaborate important pillars in developing trustworthy medical AI tools, how to marry medical intelligence and AI to enhance trust from clinicians, and showcase a range of applications of AI/ML in medical imaging.
        </p>
      </p>
    </details>

    <b>14:20 – 14:50</b> | Invited Talk #6: <b>Jayashree Kalpathy-Cramer</b>  (remote)<br>

    <!-- <br> -->
    <h3 style="color: #084DF6">Oral Session #2 [14:50 – 15:00]</h3>
    <b>14:50 – 14:55</b> | Oral Presentation #5: <b>Haochen Zhang</b> (remote): <i><b>Robust AMD Stage Grading with Exclusively OCTA Modality Leveraging 3D Volume</i></b> <br>
    <b>14:55 – 15:00</b> | Oral Presentation #6: <b>Vanessa Wirth</b> (in person): <i><b>ShaRPy: Shape Reconstruction and Hand Pose Estimation from RGB-D with Uncertainty</i></b> <br>
    <!-- <br> -->
  
    <details>
      <summary>
        <h3 style="color: #084DF6">Poster Session #2 & Coffee Break [15:00 – 16:00]</h3>
      </summary>
      <p>
        <a href="posters/ICCV_MirrorUNet_pdf24 - Zdravko Marinov.pdf"><u>1. Mirror U-Net: Marrying Multimodal Fission with Multi-task Learning for Semantic Segmentation in Medical Imaging</u></a>  <br>
        <a href="posters/Poster_upload - Gabriel Mateo Mejia.pdf"><u>2. SEPAL: Spatial Gene Expression Prediction from Local Graphs</u></a>  <br>
        3. Do CNNs need some Attention? Boosted Organ Segmentation with Attention Maps from Self-Supervised ViTs <br>
        <a href="posters/poster_CVAMD_paper06_12092023 - Linh Le.pdf"><u>4. RRc-UNet 3D for lung tumor segmentation from CT scans of Non-Small Cell Lung Cancer patients</u></a>  <br>
        <a href="posters/Chest_Xray_Poster - Faisal Ahmed.pdf"><u>5. Topo-CXR: Chest X-ray TB and Pneumonia Screening with Topological Machine Learning</u></a> <br>
        <a href="posters/cvamd_poster - Xinrong Hu.pdf"><u>6. Contrastive Image Synthesis and Self-supervised Feature Adaptation for Cross-Modality Biomedical Image segmentation</u></a>  <br>
        <a href="posters/poster-CVAMD-12 - z yu.pdf"><u>7. Cross-grained Contrastive Representation for Unsupervised Lesion Segmentation in Medical Image</u></a>  <br>
        8. Semi-supervised Quality Evaluation of Colonoscopy Procedures <br>
        9. Ensuring a connected structure for Retinal Vessels Deep-Learning Segmentation <br>
        <a href="posters/CLIPath - Jeff Lai.pdf"><u>10. CLIPath: Fine-tune CLIP with Visual Feature Fusion for Pathology Image Analysis Towards Minimizing Data Collection Efforts</u></a>  <br>
        <a href="posters/CVAMD-16-poster - reza azad.pdf"><u>11. Implicit Neural Representation in Medical Imaging: A Comparative Survey</u></a>  <br>
        <a href="posters/CVAMD2023_poster_paperID18 - Sriprabha Ramanarayanan.pdf"><u>12. HyperCoil-Recon: A Hypernetwork-based Adaptive Coil Configuration Task Switching Network for MRI Reconstruction</u></a>  <br>
        <a href="posters/CVAMD_Poster_19 - Ashay Patel.pdf"><u>13. Self-Supervised Anomaly Detection from Anomalous Training Data via Iterative Latent Token Masking</u></a>  <br>
        <a href="posters/iccv23w_poster_22 - Haochen Zhang.pdf"><u>14. Robust AMD Stage Grading with Exclusively OCTA Modality Leveraging 3D Volume</u></a>  <br>
        <a href="posters/Segmentation-based Assessment of Tumor-Vessel Involvement for Surgical Resectability Prediction of Pancreatic Ductal Adenocarcinoma - Christiaan Viviers.pdf"><u>15. Segmentation-based Assessment of Tumor-Vessel Involvement for Surgical Resectability Prediction of Pancreatic Ductal Adenocarcinoma</u></a>  <br>
        <a href="posters/CVAMD-27, Sharing is Caring Concurrent Interactive Segmentation and Model Training using a Joint Model - Ivan Mikhailov.pdf"><u>16. Sharing is Caring: Concurrent Interactive Segmentation and Model Training using a Joint Model</u></a>  <br>
        <a href="posters/CVAMD-29 - Sudipta Roy(1).pdf"><u>17. Robust MSFM Learning Network for Classification and Weakly Supervised Localization</u></a>  <br>
        <a href="posters/cvamd2023_poster_v2.3 - 정재민.pdf"><u>18. Standardized Image-Based Polysomnography Database and Deep Learning Algorithm for Sleep Stage Classification</u></a>  <br>
        <a href="posters/CVAMD2023_HwihunJeong_BlindHarmony - ­정휘훈 _ 학생 _ 전기·정보공학부.pdf"><u>19. BlindHarmony: “Blind” Harmonization for multi-site MR Image processing via Flow model</u></a>  <br>
        <a href="posters/Template_poster_CREATIS_ICCV_2023 (1) - nicolas “Emoptisie”.pdf"><u>20. SP3D: Learning Keypoint Detection and Description in 3D Medical Images</u></a>  <br>
        <a href="posters/poster_38 - qi wang.pdf"><u>21. DISGAN: Wavelet-informed discriminator guides GAN to MRI image Super-resolution with noise cleaning</u></a>  <br>
        <a href="posters/ICCV_CVAMD_Poster_40 - Adrit Rao.pdf"><u>22. Studying the Impact of Augmentations on Medical Confidence Calibration</u></a>  <br>
        <a href="posters/ICCV_CVAMD_Poster_2023_final - Weichen Huang.pdf"><u>23. Multimodal Contrastive Learning and Tabular Attention for Automated Alzheimer's Disease Prediction </u></a>  <br>
        <a href="posters/ePoster_CVAMD23_v4 - Ye Li.pdf"><u>24. Weakly Semi-supervised Detector-based Video Classification with Temporal Constraints for Lung Ultrasound</u></a>  <br>
        <a href="posters/Order Learning Vision Transformer for Cancer Classification in Pathology Images - ‍이주천[ 대학원석사과정재학 _ 전기전자공학과 ].pdf"><u>25. Order-ViT: Order Learning Vision Transformer for Cancer Classification in Pathology Images</u></a>  <br>
        <a href="posters/paper_id_46_iccv_cvamd - SHUBHAM KUMAR(1).pdf"><u>26. MIND THE CLOT: AUTOMATED LVO DETECTION ON CTA USING DEEP LEARNING</u></a>  <br>
        <a href="posters/CVAMD2023-poster - Anh Tu Nguyen.pdf"><u>27. A Comparative Study of Vision Transformer Encoders and Few-shot Learning for Medical Image Classification</u></a>  <br>
        28. RheumaVIT: transformer-based model for Automated Scoring of Hand Joints in Rheumatoid Arthritis <br>
        <a href="posters/CVAMD-49 - Sudipta Roy.pdf"><u>29. AW-Net: A Novel Fully Connected Attention-based Medical Image Segmentation Model</u></a>  <br>
        30. Geodesic Regression Characterizes 3D Shape Changes in the Female Brain During Menstruation <br>
        <a href="posters/Poster_ICCVworkshop_2023 - Laura Galvez Jimenez.pdf"><u>31. Computational Evaluation of the Combination of Semi-Supervised and Active Learning for Histopathology Image Segmentation with Missing Annotations </u></a>  <br>
        <a href="posters/ICCV2023-2 - Quang-Hien Kha.pdf"><u>32. Towards Robust Natural-looking Mammography Lesion Synthesis On Ipsilateral Dual-views Breast Cancer Analysis</u></a>  <br>
        <a href="posters/ICCV-poster - SIQI WANG.pdf"><u>33. End-to-End Deep Learning for Reconstructing Segmented 3D CT Image from Multi-Energy X-ray Projections</u></a>  <br>
        <a href="posters/Yourim Choi_ICCV CVAMD - ­최유림 _ 학생 _ 데이터사이언스학과.pdf"><u>34. SlAction: Non-intrusive, Lightweight Obstructive Sleep Apnea Detection using Infrared Video</u></a>  <br>
        <a href="posters/ICCV_CVAMD_Poster - JJ L.pdf"><u>35. Combating Coronary Calcium Scoring Bias for Non-gated CT by Semantic Learning on Gated CT</u></a>  <br>
        36. Comprehensive Multimodal Segmentation in Medical Imaging: Combining YOLOv8 with SAM and HQ-SAM Models <br>
        37. Semantic Parsing of Colonoscopy Videos with Multi-Label Temporal Networks <br>
        <a href="posters/iccv_poster_final - Sidney Bender.pdf"><u>38. Towards Fixing Clever-Hans Predictors with Counterfactual Knowledge Distillation</u></a>  <br>
        <a href="posters/poster-CVAMD-62 - Eva Pachetti.pdf"><u>39. Causality-Driven One-Shot Learning for Prostate Cancer Grading from MRI</u></a>  <br>
        <a href="posters/sharpy_poster_ver3 - Vanessa Wirth.pdf"><u>40. ShaRPy:Shape Reconstruction and Hand Pose Estimation From RGB-D with Uncertainty</u></a> <br>
        41. An Empirical Analysis for Zero-Shot Multi-Label Classification on COVID-19 CT Scans and Uncurated Reports <br>
        42. Fusion Approaches to Predict Post-stroke Aphasia Recovery from Multimodal Neuroimaging Data <br>
        43. Automated Biomarker Detection in Diagnostics of Colorectal Cancer <br>
        <a href="posters/CVAMD-72-poster - reza azad.pdf"><u>44. Self-supervised Semantic Segmentation: Consistency over Transformation</u></a>  <br>
        <a href="posters/ICCV_poster_final - Milad Sikaroudi.pdf"><u>45. ALFA: Leveraging All Levels of Feature Abstraction for Enhancing the Generalization of Histopathology Image Classification Across Unseen Hospitals</u></a>  <br>
        46. Pathology-Based Ischemic Stroke Etiology Classification via Clot Composition Guided Multiple Instance Learning <br>
        47. Enhancing Medical Image Segmentation: Optimizing Cross-Entropy Weights and Post-Processing with Autoencoders <br>
        <a href="posters/LookingBeyondWhatYouSee_Poster_CVMAD_2023 - Dana Moukheiber.pdf"><u>48. Looking Beyond What You See: An empirical analysis on subgroup intersectional fairness for multi-label chest x-rays classification using social determinants of racial health inequities</u></a>  <br>
        <a href="posters/Poster_ICCV_Ivan-2 - Billy Peralta.pdf"><u>49. Double pre-training for detecting fetal heart diseases with Deep Learning: A Chilean case</u></a>  <br>
        <a href="posters/CVAMD83 - Sajith R.pdf"><u>50. Using Large Text To Image Models with Structured Prompts for Skin Disease Identification: A Case Study</u></a>  <br>
        <a href="posters/chexfusion poster - Dongkyun Kim.pdf"><u>51. CheXFusion: Effective Fusion of Multi-View Features using Transformers for Long-Tailed Chest X-Ray Classification</u></a>  <br>
        <a href="posters/poster_CVAMD - 박원기(1).pdf"><u>52. Robust Asymmetric Loss for Multi-Label Long-Tailed Learning</u></a>  <br>
        53. How Can We Tame the Long-Tail of Chest X-ray Datasets? <br>
        54. Effect of Stage Training for Long-Tailed Multi-Label Image Classification <br>
        <a href="posters/Poster - feng hong.pdf"><u>55. Bag of Tricks for Long-Tailed Multi-Label Classification on Chest X-Rays </u></a>  <br>
        56. Advanced Augmentation and Ensemble Approaches for Classifying Long-Tailed Multi-Label Chest X-Rays <br>
        57. An Optimized Ensemble-based Framework for Multi-Label Long-Tailed Classification on Chest X-rays <br>
        58. Multi-Label Long-Tailed Classification on Chest X-Rays by upgrading ML-GCN <br>
        <a href="posters/ICCV_poster_cvamd-96-new-A0 - Changhyun Kim.pdf"><u>59. Chest X-Ray Feature Pyramid Sum Model with Diseased Area Data Augmentation Method</u></a>  <br>
      </p>  
    </details>

    <h3 style="color: #084DF6">Afternoon Session #2 [16:00 – 17:00]</h3>

    <details>
      <summary>
        <b>16:00 – 16:30</b> | Invited Talk #7: <b>Mert Sabuncu</b> (remote):
        <b><i>KeyMorph: Robust, interpretable, and controllable multi-modal registration</i></b>
      </summary>
        <p>
          <b>Abstract:</b> Over the last 7+ years, deep learning has been transforming medical imaging, from enhancing acquisition to maximizing downstream utility of scans. Much of this progress relies on supervised learning approaches with “black box” models. In this talk, I will show an example of recent work from my group where we move beyond this traditional paradigm to develop tools designed for the unique considerations of medical imaging, in a classic problem setting: multi-modal image registration. I will describe a novel architecture we developed, coined KeyMorph, that affords the user robustness, control, and interpretability.
        </p>
      </p>
    </details>

    <details>
      <summary>
        <b>16:30 – 17:00</b> | Invited Talk #8: <b>Adam Yala</b> (remote):
        <b><i>Seeing into the Future:  ML for personalized screening</i></b>
      </summary>
        <p>
          <b>Abstract:</b> For multiple diseases, early detection significantly improves patient outcomes. This motivates considerable investments in population-wide screening programs, such as mammography for breast cancer and low-dose CT for lung cancer. To be effective and economically viable, these programs must find the right balance between early detection and overscreening. This capacity builds on two complementary technologies: (1) the ability to accurately assess patient risk at a given time point and (2) the ability to design screening regimens based on this risk. Moreover, these tools must obtain consistent performance across diverse populations and adapt to new clinical requirements while learning from limited datasets. In this talk, I’ll discuss approaches to address these challenges in cancer risk assessment from imaging and personalized screening policy design. We’ve demonstrated that these clinical models offer significant improvements over the current standard of care across globally diverse patient populations, and our image-based tools now underly prospective trials.
        </p>
      </p>
    </details>
    <br>
    <!-- <b>17:00 – 17:30</b> | Invited Talk #9 <br> -->

    <!-- <br> -->
    <h3 style="color: #084DF6">Closing Remarks [17:00 – 17:10]</h3>
    
  </div>
</div>

<br>

<div class="container", id="invited_speakers">
  <h2>Invited Speakers</h2>
  <div class="instructor">
    <a href="https://zitniklab.hms.harvard.edu/">
      <div class="instructorphoto"><img src="images/marinka.jpg"></div>
      Marinka Zitnik
    </a><br>
    <small>Assistant Professor, Harvard Medical School</small>
  </div>
  
  <div class="instructor">
    <a href="https://qtim-lab.github.io/">
      <div class="instructorphoto"><img src="images/jayashree.jpg"></div>
      Jayashree Kalpathy-Cramer
    </a><br>
    <small>Professor, School of Medicine, University of Colorado</small>
  </div>

  <div class="instructor">
    <a href="https://www.aimi.pitt.edu/people/shandong-wu-phd">
      <div class="instructorphoto"><img src="images/shandong.jpg"></div>
      Shandong Wu
    </a><br>
    <small>Associate Professor, University of Pittsburgh</small>
  </div>

  <br>

  <div class="instructor">
    <a href="https://sabuncu.engineering.cornell.edu/">
      <div class="instructorphoto"><img src="images/mert.jpg"></div>
      Mert Sabuncu
    </a><br>
    <small>Professor, Cornell University</small>
  </div>

  <div class="instructor">
    <a href="https://www.spchopra.org/">
      <div class="instructorphoto"><img src="images/sumit.jpg"></div>
      Sumit Chopra
    </a><br>
    <small>Associate Professor, NYU</small>
  </div>

  <div class="instructor">
    <a href="https://www.holgerroth.com/">
      <div class="instructorphoto"><img src="images/holger.jpg"></div>
      Holger Roth
    </a><br>
    <small>Senior Research Scientist, NVIDIA</small>
  </div>

  <br>
  
  <div class="instructor">
    <a href="https://www.adamyala.org/">
      <div class="instructorphoto"><img src="images/adam.jpg"></div>
      Adam Yala
    </a><br>
    <small>Assistant Professor, UC Berkeley & UCSF</small>
  </div>

  <div class="instructor">
    <a href="https://cs.stanford.edu/~sanmi/">
      <div class="instructorphoto"><img src="images/sanmi.jpg"></div>
      Sanmi Koyejo
    </a><br>
    <small>Assistant Professor, Stanford University</small>
  </div>

  <div class="instructor">
    <a href="https://liyueshen.engin.umich.edu/research/">
      <div class="instructorphoto"><img src="images/liyue.png"></div>
      Liyue Shen
    </a><br><small>Assistant Professor, University of Michigan</small><br></div>
  </div>
</div>

<br>

<div class="container", id="call_for_paper">
  <h2>Call for Submissions</h2>
  <div class="submissions">
    <p>The workshop considers two types of submissions: (1) long papers up to 8 pages excluding references; (2) extended abstracts up to 4 pages excluding references. We invite both types of submissions for oral and poster presentations during the workshop. Topics include (but are not limited to):</p>
    <p>
    <ul>
      <li>Advances in disease diagnosis and management with computer vision</li>
      <li>Foundation models in medical computer vision</li>
      <li>Fairness, robustness and generalization of medical vision models</li>
      <li>Embedding medical knowledge in computer vision systems</li>
      <li>Designing medical computer vision systems coherent with clinical reasoning</li>
      <li>Predicting clinical outcomes from medical image analysis</li>
      <li>Designing evaluation protocols under various real-world clinical scenarios</li>
      <li>Longitudinal study with medical computer vision</li>
      <li>Organ and lesion segmentation/detection</li>
      <li>Generating diagnostic reports from medical images</li>
      <li>Life-long learning and active learning in medical computer vision</li>
      <li>Self-/semi-/weakly-supervised medical image analysis</li>
    </ul>
    </p>
    <p>
      Acceptance and selection of orals and posters will be based on the fit to the workshop and decisions will be made by the program and organization committee. 
      <b>
        <!-- Submitted work can be of preliminary nature and we also invite perspectives and position papers to generate discussions about recent trends and major challenges.  -->
        The accepted long papers will be published in conjunction with ICCV 2023 proceedings.
      </b>
    </p>
    
    <b><font style="color:firebrick">Submission Instructions:</font></b>
    <ul>
      <li>Submission using <a href="https://cmt3.research.microsoft.com/CVAMD2023" target="_blank">CMT submission system</a></li>
      <li>Please use <a href="https://iccv2023.thecvf.com/iccv2023authorkit-38--NQ.php">ICCV 2023 submission template</a></li>
    </ul>

    <p>
      Authors should submit a PDF version that needs to be <b>ANONYMOUS</b>. Submitting a paper to the workshop means that if the paper is accepted at least one author commits to presenting it at the workshop.
    </p> 

  </div>
</div>

<br>

<div class="container", id="important_dates">
  <h2>Important Dates</h2>
  <br/>
  <table class="table table-striped">
    <tbody>
    <tr>
        <td style="width:50%">Paper submission deadline</td>
        <td><del>7/15/2023</del> 7/20/2023, AoE</td>
    </tr>
    <tr>
        <td>Paper acceptance notification</td>
        <td><del>8/6/2023</del> 8/7/2023, AoE</td>
    </tr>
    <tr>
        <td>Camera-ready papers due</td>
        <td>8/20/2023</td>
    </tr>
    <tr>
        <td>ICCV CVAMD workshop</td>
        <td>10/2/2023</td>
    </tr>
    <tr id="schedule">
        <td></td>
        <td></td>
    </tr>
    </tbody>
</table>
</div>

<br>

<div class="container", id="organizers">
  <h2>Organizers</h2>
  <div class="instructorsmall">
    <a href="https://www.mit.edu/~yuzhe/">
      <div class="instructorphotosmall"><img src="images/yuzhe_yang.jpg"></div>
      <div>Yuzhe Yang<br><small>MIT</small><br></div>
    </a>
  </div>
  
  <div class="instructorsmall">
    <a href="https://gholste.me">
      <div class="instructorphotosmall"><img src="images/greg_holste.jpg"></div>
      <div>Gregory Holste<br><small>UT Austin</small><br></div>
    </a>
  </div>

  <div class="instructorsmall">
    <a href="">
      <div class="instructorphotosmall"><img src="images/fuying_wang.jpg"></div>
      <div>Fuying Wang<br><small>HKU</small><br></div>
    </a>
  </div>

  <div class="instructorsmall">
    <a href="https://yulequan.github.io/">
      <div class="instructorphotosmall"><img src="images/lequan_yu.jpg"></div>
      <div>Lequan Yu<br><small>HKU</small><br></div>
    </a>
  </div>
  
  <div class="instructorsmall">
    <a href="https://cse.hkust.edu.hk/~jhc/">
      <div class="instructorphotosmall"><img src="images/hao_chen.jpg"></div>
      <div>Hao Chen<br><small>HKUST</small><br></div>
    </a>
  </div>

  <div class="instructorsmall">
    <a href="https://www.helmholtz.ai/themenmenue/our-research/research-groups/peng-group/index.html">
      <div class="instructorphotosmall"><img src="images/tingying_peng.jpg"></div>
      <div>Tingying Peng<br><small>Helmholtz Munich</small><br></div>
    </a>
  </div>

  <div class="instructorsmall">
    <a href="http://faculty.ist.psu.edu/suh972/">
      <div class="instructorphotosmall"><img src="images/xiaolei_huang.jpg"></div>
      <div>Xiaolei Huang<br><small>Penn State University</small><br></div>
    </a>
  </div>

  <div class="instructorsmall">
    <a href="https://penglab.weill.cornell.edu/">
      <div class="instructorphotosmall"><img src="images/yifan_peng.jpg"></div>
      <div>Yifan Peng<br><small>Weill Cornell Medicine</small><br></div>
    </a>
  </div>

  <div class="instructorsmall">
    <a href="https://vita-group.github.io">
      <div class="instructorphotosmall"><img src="images/atlas_wang.jpg"></div>
      <div>Atlas Wang<br><small>UT Austin</small><br></div>
    </a>
  </div>

  <div class="instructorsmall">
    <a href="https://yuyinzhou.github.io"◊>
      <div class="instructorphotosmall"><img src="images/yuyin_zhou.jpg"></div>
      <div>Yuyin Zhou<br><small>UC Santa Cruz</small><br></div>
    </a>
  </div>

</div>

<br>

<div class="container", id="workshop_sponsor">
  <h2>Workshop Sponsor</h2>
  <br>
  <div style="text-align: left;"><img src="images/aij.jpeg" width="300px" alt="aij_icon"></div>
  <br>
  <div style="text-align: left;"><a href="https://www.elsevier.com/locate/artint" target="_blank">The Artificial Intelligence Journal (AIJ) </a></div>
</div>

<br>

<div class="container", id="supporting_organization">
  <h2>Supporting Organization</h2>
  <br>
  <div style="text-align: left;"><img src="images/miccai_icon.png" width="400px" alt="MICCAI_icon"></div>
  <br>
  <div style="text-align: left;"><a href="http://www.miccai.org/events/endorsed-and-sponsored-events/" target="_blank">MICCAI Endorsed Event</a></div>
</div>

<br>

<div class="containersmall">
    <center><p>
      <b>Code of Conduct:</b> CVAMD 2023 will adopt the <a href=http://www.miccai.org/about-miccai/code-of-conduct-2>MICCAI Code of Conduct</a> and <a href=http://www.miccai.org/about-miccai/scientific-code-of-ethics>MICCAI Scientific Code of Ethics</a>.
    </p></center>
    <center><p>This webpage template is by courtesy of the awesome <a href="https://gkioxari.github.io/" target="_blank">Georgia</a>.</center></p>
    <!-- <p>This comeptition is sponsored in part by the Artifical Intelligence Journal (AIJ).</p>
    <center><img src="https://aij.ijcai.org/wp-content/uploads/2021/07/ARTINT_Logo2_c_web_more.jpg" width="10%"></img></center> -->
</div>
<!-- 
<div class="container", id="reviewers">
  <h2>Acknowledgement for Rreviewers</h2>
</div> -->

<br>

</body>
</html>
